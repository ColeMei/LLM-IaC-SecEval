{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e32593d",
   "metadata": {},
   "source": [
    "# ğŸ¤– LLM Post-Filter Experiment: GLITCH+LLM Pipeline\n",
    "\n",
    "**Focus**: Evaluate **GLITCH + LLM** hybrid approach vs **GLITCH-only** baseline.\n",
    "\n",
    "## ğŸ”¬ Experiment Pipeline:\n",
    "\n",
    "1. **Data Preparation**: GLITCH detections + context extracted *(01_data_extraction.py)*\n",
    "2. **LLM Filtering**: Apply the selected LLM post-filtering  \n",
    "3. **Performance Evaluation**: Calculate precision/recall improvements\n",
    "\n",
    "## ğŸ¯ Expected Outcomes:\n",
    "- **Precision**: 50-300% improvement\n",
    "- **Recall**: >90% retention  \n",
    "- **FP Reduction**: Significant decrease in false alarms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e52b23a",
   "metadata": {},
   "source": [
    "## ğŸ”§ Setup and Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fe85201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Using provider=openai | model=gpt-4o | base_url=None\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”§ Manual provider/model override (optional)\n",
    "# Edit these values to force a specific provider/model for this session.\n",
    "# Supported providers: \"openai\", \"anthropic\", \"ollama\", \"openai_compatible\"\n",
    "provider = \"openai\"\n",
    "model = \"gpt-4o\"   # examples: \"gpt-4o\", \"claude-3-5-sonnet-latest\", \"codellama:7b\"\n",
    "base_url = None          # for ollama or openai-compatible, e.g. \"http://localhost:11434\" or \"https://api.x.ai/v1\"\n",
    "\n",
    "import os\n",
    "os.environ[\"LLM_PROVIDER\"] = provider\n",
    "os.environ[\"LLM_MODEL\"] = model\n",
    "if base_url:\n",
    "    os.environ[\"LLM_BASE_URL\"] = str(base_url)\n",
    "else:\n",
    "    os.environ.pop(\"LLM_BASE_URL\", None)\n",
    "\n",
    "print(f\"âœ… Using provider={os.getenv('LLM_PROVIDER')} | model={os.getenv('LLM_MODEL')} | base_url={os.getenv('LLM_BASE_URL')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5801de0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ  Project root: /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval\n",
      "ğŸ“ Working directory: /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval/experiments/llm_postfilter/notebooks\n",
      "ğŸ”‘ Provider: OpenAI | Model: gpt-4o | API key found: True\n",
      "ğŸš€ LLM Post-Filter Experiment Ready!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Add llm-postfilter modules to path\n",
    "project_root = Path.cwd().parent.parent.parent\n",
    "sys.path.append(str(project_root / \"src\"))\n",
    "\n",
    "# Import llm-postfilter pipeline components\n",
    "from llm_postfilter import (\n",
    "    GLITCHLLMFilter, \n",
    "    HybridEvaluator,\n",
    "    SecuritySmellPrompts,\n",
    "    SecuritySmell,\n",
    "    Provider,\n",
    ")\n",
    "\n",
    "print(f\"ğŸ  Project root: {project_root}\")\n",
    "print(f\"ğŸ“ Working directory: {Path.cwd()}\")\n",
    "\n",
    "# Optional: set provider/model for downstream notebook via env\n",
    "os.environ[\"LLM_PROVIDER\"] = \"openai\"\n",
    "os.environ[\"LLM_MODEL\"] = \"gpt-4o\"\n",
    "\n",
    "# Provider/model selection via env vars with sensible defaults\n",
    "provider = os.getenv(\"LLM_PROVIDER\", Provider.OPENAI.value)\n",
    "model = os.getenv(\"LLM_MODEL\", \"gpt-4o-mini\")\n",
    "base_url = os.getenv(\"LLM_BASE_URL\")  # for ollama or openai-compatible\n",
    "\n",
    "# API keys per provider\n",
    "api_key = None\n",
    "if provider == Provider.OPENAI.value:\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    print(f\"ğŸ”‘ Provider: OpenAI | Model: {model} | API key found: {bool(api_key)}\")\n",
    "elif provider == Provider.ANTHROPIC.value:\n",
    "    api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    print(f\"ğŸ”‘ Provider: Anthropic | Model: {model} | API key found: {bool(api_key)}\")\n",
    "elif provider == Provider.OLLAMA.value:\n",
    "    print(f\"ğŸ”‘ Provider: Ollama | Model: {model} | Base URL: {base_url or 'http://localhost:11434'}\")\n",
    "elif provider == Provider.OPENAI_COMPATIBLE.value:\n",
    "    api_key = os.getenv(\"OPENAI_COMPATIBLE_API_KEY\")\n",
    "    print(f\"ğŸ”‘ Provider: OpenAI-compatible | Model: {model} | Base URL: {base_url}\")\n",
    "else:\n",
    "    print(f\"âŒ Unsupported provider: {provider}\")\n",
    "\n",
    "print(\"ğŸš€ LLM Post-Filter Experiment Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa31952a",
   "metadata": {},
   "source": [
    "## ğŸ“ Step 1: Load Context-Enhanced Data\n",
    "\n",
    "**Load detection files with code context prepared by 01_data_extraction.py**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "155fabcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Found 6 context-enhanced files:\n",
      "  ğŸ“„ puppet_suspicious_comment_detections_with_context.csv: 23 detections (9 TP, 14 FP, 23 with context)\n",
      "  ğŸ“„ puppet_use_of_weak_cryptography_algorithms_detections_with_context.csv: 7 detections (4 TP, 3 FP, 7 with context)\n",
      "  ğŸ“„ puppet_hard_coded_secret_detections_with_context.csv: 66 detections (9 TP, 57 FP, 66 with context)\n",
      "  ğŸ“„ chef_use_of_weak_cryptography_algorithms_detections_with_context.csv: 2 detections (1 TP, 1 FP, 2 with context)\n",
      "  ğŸ“„ chef_hard_coded_secret_detections_with_context.csv: 46 detections (9 TP, 37 FP, 46 with context)\n",
      "  ğŸ“„ chef_suspicious_comment_detections_with_context.csv: 10 detections (4 TP, 6 FP, 10 with context)\n",
      "\n",
      "âœ… Context-enhanced data ready for LLM analysis\n"
     ]
    }
   ],
   "source": [
    "# Setup directories\n",
    "data_dir = project_root / \"experiments/llm_postfilter/data\"\n",
    "context_dir = data_dir / \"with_context\"\n",
    "\n",
    "# Find context-enhanced files\n",
    "context_enhanced_files = list(context_dir.glob(\"*_with_context.csv\"))\n",
    "\n",
    "if context_enhanced_files:\n",
    "    print(f\"ğŸ“ Found {len(context_enhanced_files)} context-enhanced files:\")\n",
    "    for file in context_enhanced_files:\n",
    "        df = pd.read_csv(file)\n",
    "        tp_count = df['is_true_positive'].sum()\n",
    "        fp_count = len(df) - tp_count\n",
    "        context_success = df['context_success'].sum()\n",
    "        print(f\"  ğŸ“„ {file.name}: {len(df)} detections ({tp_count} TP, {fp_count} FP, {context_success} with context)\")\n",
    "    \n",
    "    print(f\"\\nâœ… Context-enhanced data ready for LLM analysis\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ No context-enhanced files found!\")\n",
    "    print(\"â¡ï¸  Run 01_data_extraction.py first to prepare the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d79241f",
   "metadata": {},
   "source": [
    "## ğŸ“ Step 2: Review LLM Prompt Design\n",
    "\n",
    "Review the formal security smell definitions used for LLM evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "449ee4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Security Smell Definitions for LLM\n",
      "========================================\n",
      "\n",
      "ğŸ“Œ Hard-coded secret\n",
      "  A hard-coded secret is a security vulnerability where sensitive information such as passwords, API keys, tokens, certificates, or other credentials are directly embedded in the source code as literal strings or variables, rather than being securely stored and retrieved from external configuration systems, environment variables, or secret management services.\n",
      "  \n",
      "  Key characteristics:\n",
      "  ... (128 words total)\n",
      "\n",
      "ğŸ“Œ Suspicious comment\n",
      "  A suspicious comment is a code comment that indicates potential security issues, incomplete security implementations, or areas requiring security attention. These comments often signal unfinished work, security bypasses, or acknowledged vulnerabilities that may pose risks.\n",
      "  \n",
      "  Key characteristics:\n",
      "  ... (119 words total)\n",
      "\n",
      "ğŸ“Œ Use of weak cryptography algorithms\n",
      "  Use of weak cryptography algorithms refers to the implementation or configuration of cryptographic functions that are known to be vulnerable, deprecated, or insufficient for current security standards. This includes both algorithmically weak ciphers and poor cryptographic practices.\n",
      "  \n",
      "  Key characteristics:\n",
      "  ... (133 words total)\n",
      "\n",
      "âœ… 3 smell categories with formal definitions ready\n"
     ]
    }
   ],
   "source": [
    "# Display formal definitions for each security smell\n",
    "print(\"ğŸ“ Security Smell Definitions for LLM\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for smell in SecuritySmell:\n",
    "    definition = SecuritySmellPrompts.DEFINITIONS[smell]\n",
    "    lines = definition.strip().split('\\n')[:3]\n",
    "    print(f\"\\nğŸ“Œ {smell.value}\")\n",
    "    for line in lines:\n",
    "        print(f\"  {line}\")\n",
    "    print(f\"  ... ({len(definition.split())} words total)\")\n",
    "\n",
    "print(f\"\\nâœ… {len(SecuritySmell)} smell categories with formal definitions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf30b6d",
   "metadata": {},
   "source": [
    "## ğŸ”§ Step 3: Initialize LLM Pipeline\n",
    "\n",
    "Setup GLITCH+LLM hybrid detection pipeline with the selected provider/model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89029028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 14:12:46,791 - llm_postfilter.llm_client - INFO - Initialized OpenAI client with model: gpt-4o-mini\n",
      "2025-08-10 14:12:46,793 - llm_postfilter.llm_filter - INFO - Initialized GLITCH+LLM filter pipeline\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Initializing GLITCH+LLM pipeline...\n",
      "âœ… Pipeline ready:\n",
      "  ğŸ¤– Provider: openai\n",
      "  ğŸ¤– Model: gpt-4o-mini\n",
      "  ğŸ“Š Results â†’ /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval/experiments/llm_postfilter/data/llm_results\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM filter pipeline\n",
    "# For OpenAI/Anthropic/OpenAI-compatible, an API key is required; for Ollama, it's not\n",
    "if (provider == Provider.OLLAMA.value) or (api_key):\n",
    "    print(\"ğŸ”§ Initializing GLITCH+LLM pipeline...\")\n",
    "    \n",
    "    llm_filter = GLITCHLLMFilter(\n",
    "        project_root=project_root,\n",
    "        api_key=api_key,\n",
    "        model=model,\n",
    "        provider=provider,\n",
    "        base_url=base_url,\n",
    "    )\n",
    "    evaluator = HybridEvaluator(project_root)\n",
    "    \n",
    "    # Setup directories\n",
    "    results_dir = data_dir / \"llm_results\"\n",
    "    results_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    print(\"âœ… Pipeline ready:\")\n",
    "    print(f\"  ğŸ¤– Provider: {provider}\")\n",
    "    print(f\"  ğŸ¤– Model: {llm_filter.llm_client.model}\")\n",
    "    print(f\"  ğŸ“Š Results â†’ {results_dir}\")\n",
    "else:\n",
    "    print(\"âŒ Pipeline initialization failed - missing credentials\")\n",
    "    print(\"Set appropriate API key env var (OPENAI_API_KEY / ANTHROPIC_API_KEY / OPENAI_COMPATIBLE_API_KEY) or use Ollama\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891df435",
   "metadata": {},
   "source": [
    "## ğŸš€ Step 4: Run LLM Post-Filtering\n",
    "\n",
    "Apply LLM post-filtering to GLITCH detections and measure improvements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b00380",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ((provider == Provider.OLLAMA.value) or api_key) and 'context_enhanced_files' in locals():\n",
    "    print(f\"ğŸ” Processing {len(context_enhanced_files)} context-enhanced files:\")\n",
    "    for file in context_enhanced_files:\n",
    "        df = pd.read_csv(file)\n",
    "        tp_count = df['is_true_positive'].sum()\n",
    "        fp_count = len(df) - tp_count\n",
    "        context_success = df['context_success'].sum()\n",
    "        print(f\"  ğŸ“ {file.name}: {len(df)} detections ({tp_count} TP, {fp_count} FP)\")\n",
    "    \n",
    "    print(f\"\\nğŸš€ Starting LLM post-filtering...\")\n",
    "    \n",
    "    # Process each context-enhanced file\n",
    "    filtered_results = {}\n",
    "    \n",
    "    for i, context_file in enumerate(context_enhanced_files):\n",
    "        print(f\"\\nğŸ”„ Processing {i+1}/{len(context_enhanced_files)}: {context_file.name}\")\n",
    "        \n",
    "        try:\n",
    "            # Run LLM filtering\n",
    "            filtered_df = llm_filter.filter_detections(context_file, results_dir)\n",
    "            filtered_results[context_file.stem] = filtered_df\n",
    "            \n",
    "            # Summary stats\n",
    "            total = len(filtered_df)\n",
    "            kept = filtered_df['keep_detection'].sum()\n",
    "            original_tp = filtered_df['is_true_positive'].sum() \n",
    "            kept_tp = filtered_df[filtered_df['keep_detection']]['is_true_positive'].sum()\n",
    "            \n",
    "            print(f\"âœ… Kept {kept}/{total} ({kept/total:.1%}) | TP retention: {kept_tp}/{original_tp} ({kept_tp/original_tp:.1%})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error: {e}\")\n",
    "            logger.error(f\"Failed to process {context_file}: {e}\")\n",
    "    \n",
    "    print(f\"\\nğŸ‰ LLM filtering completed! Results â†’ {results_dir}\")\n",
    "    \n",
    "elif provider != Provider.OLLAMA.value and not api_key:\n",
    "    print(\"âŒ Skipping - API key required for selected provider\")\n",
    "else:\n",
    "    print(\"âŒ Skipping - no context files (run context extraction first)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef5c3aa",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Step 5: Evaluate Performance Improvement\n",
    "\n",
    "Calculate precision, recall, and F1 improvements from LLM post-filtering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc577f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "if api_key and 'filtered_results' in locals():\n",
    "    print(\"ğŸ“Š Evaluating GLITCH vs GLITCH+LLM Performance\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Organize results by IaC tool\n",
    "    evaluation_results = {}\n",
    "    \n",
    "    for tool in ['chef', 'puppet']:\n",
    "        tool_filtered_dfs = []\n",
    "        for key, filtered_df in filtered_results.items():\n",
    "            if key.startswith(tool):\n",
    "                tool_filtered_dfs.append(filtered_df)\n",
    "        \n",
    "        if tool_filtered_dfs:\n",
    "            tool_results = evaluator.evaluate_iac_tool(tool_filtered_dfs, tool.title())\n",
    "            evaluation_results[tool] = tool_results\n",
    "    \n",
    "    # Save evaluation results\n",
    "    evaluation_dir = results_dir / \"evaluation\"\n",
    "    evaluation_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    if evaluation_results:\n",
    "        summary_df = evaluator.save_evaluation_results(evaluation_results, evaluation_dir)\n",
    "        \n",
    "        print(\"\\nğŸ¯ EXPERIMENT RESULTS\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        # Display key findings\n",
    "        for _, row in summary_df.iterrows():\n",
    "            tool = row['IaC_Tool']\n",
    "            smell = row['Security_Smell']\n",
    "            baseline_precision = row['Baseline_Precision']\n",
    "            llm_precision = row['LLM_Precision']\n",
    "            precision_improvement = row['Precision_Improvement']\n",
    "            fp_reduction = row['FP_Reduction']\n",
    "            tp_retention = row['TP_Retention']\n",
    "            \n",
    "            print(f\"\\nğŸ“Œ {tool} - {smell}:\")\n",
    "            print(f\"  Precision: {baseline_precision:.3f} â†’ {llm_precision:.3f} ({precision_improvement:+.1%})\")\n",
    "            print(f\"  FPâ†“: {fp_reduction:.1%} | TP retained: {tp_retention:.1%}\")\n",
    "        \n",
    "        # Overall improvements\n",
    "        avg_precision_improvement = summary_df['Precision_Improvement'].mean()\n",
    "        avg_fp_reduction = summary_df['FP_Reduction'].mean()\n",
    "        avg_tp_retention = summary_df['TP_Retention'].mean()\n",
    "        \n",
    "        print(f\"\\nğŸš€ OVERALL OUTCOMES:\")\n",
    "        print(f\"  ğŸ“ˆ Precision improvement: {avg_precision_improvement:+.1%}\")\n",
    "        print(f\"  ğŸ“‰ FP reduction: {avg_fp_reduction:.1%}\")\n",
    "        print(f\"  ğŸ¯ TP retention: {avg_tp_retention:.1%}\")\n",
    "        \n",
    "        print(f\"\\nğŸ’¾ Detailed results â†’ {evaluation_dir}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ No evaluation results available\")\n",
    "        \n",
    "else:\n",
    "    print(\"â­ï¸ Skipping evaluation - run LLM filtering first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224034f6",
   "metadata": {},
   "source": [
    "## ğŸ“ Generated Files & Transparency\n",
    "\n",
    "Complete experimental transparency through intermediate files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7ad639",
   "metadata": {
    "lines_to_next_cell": 3
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ“ Generated Files & Transparency\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(\"\\nğŸ” Context Files (LLM input):\")\n",
    "if 'context_dir' in locals():\n",
    "    context_files = list(context_dir.glob(\"*.csv\"))\n",
    "    for file in context_files:\n",
    "        size_kb = file.stat().st_size // 1024\n",
    "        print(f\"  ğŸ“„ {file.name} ({size_kb} KB)\")\n",
    "    print(f\"  ğŸ“ {context_dir}\")\n",
    "else:\n",
    "    print(\"  âŒ No context files generated\")\n",
    "\n",
    "print(\"\\nğŸ¤– LLM Results:\")\n",
    "if 'results_dir' in locals() and results_dir.exists():\n",
    "    result_files = list(results_dir.glob(\"*.csv\")) + list(results_dir.glob(\"*.json\"))\n",
    "    for file in result_files:\n",
    "        size_kb = file.stat().st_size // 1024\n",
    "        if file.name.endswith(\"_prompts_and_responses.json\"):\n",
    "            print(f\"  ğŸ“ {file.name} ({size_kb} KB) - Full prompts & LLM responses\")\n",
    "        elif file.name.endswith(\"_llm_filtered.csv\"):\n",
    "            print(f\"  ğŸ“Š {file.name} ({size_kb} KB) - Filtered detections\")\n",
    "        else:\n",
    "            print(f\"  ğŸ“„ {file.name} ({size_kb} KB)\")\n",
    "    print(f\"  ğŸ“ {results_dir}\")\n",
    "else:\n",
    "    print(\"  âŒ No LLM results generated\")\n",
    "\n",
    "print(\"\\nğŸ“Š Evaluation:\")\n",
    "if 'evaluation_dir' in locals() and evaluation_dir.exists():\n",
    "    eval_files = list(evaluation_dir.glob(\"*.csv\")) + list(evaluation_dir.glob(\"*.json\"))\n",
    "    for file in eval_files:\n",
    "        size_kb = file.stat().st_size // 1024\n",
    "        print(f\"  ğŸ“„ {file.name} ({size_kb} KB)\")\n",
    "    print(f\"  ğŸ“ {evaluation_dir}\")\n",
    "else:\n",
    "    print(\"  âŒ No evaluation results generated\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Full transparency: code snippets, prompts, LLM decisions, metrics\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
