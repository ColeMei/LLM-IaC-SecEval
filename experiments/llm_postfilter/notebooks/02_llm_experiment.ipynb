{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e32593d",
   "metadata": {},
   "source": [
    "# ü§ñ LLM Post-Filter Experiment: GLITCH+LLM Pipeline\n",
    "\n",
    "**Focus**: Evaluate **GLITCH + LLM** hybrid approach vs **GLITCH-only** baseline.\n",
    "\n",
    "## üî¨ Experiment Pipeline:\n",
    "\n",
    "1. **Data Preparation**: GLITCH detections + context extracted *(01_data_extraction.py)*\n",
    "2. **LLM Filtering**: Apply the selected LLM post-filtering  \n",
    "3. **Performance Evaluation**: Calculate precision/recall improvements\n",
    "\n",
    "## üéØ Expected Outcomes:\n",
    "- **Precision**: 50-300% improvement\n",
    "- **Recall**: >90% retention  \n",
    "- **FP Reduction**: Significant decrease in false alarms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e52b23a",
   "metadata": {},
   "source": [
    "## üîß Setup and Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fe85201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using provider=openai | model=gpt-4o | base_url=None\n"
     ]
    }
   ],
   "source": [
    "# üîß Manual provider/model override (optional)\n",
    "# Edit these values to force a specific provider/model for this session.\n",
    "# Supported providers: \"openai\", \"anthropic\", \"ollama\", \"openai_compatible\"\n",
    "provider = \"openai\"\n",
    "model = \"gpt-4o\"   # examples: \"gpt-4o\", \"claude-3-5-sonnet-latest\", \"codellama:7b\"\n",
    "base_url = None          # for ollama or openai-compatible, e.g. \"http://localhost:11434\" or \"https://api.x.ai/v1\"\n",
    "\n",
    "import os\n",
    "os.environ[\"LLM_PROVIDER\"] = provider\n",
    "os.environ[\"LLM_MODEL\"] = model\n",
    "if base_url:\n",
    "    os.environ[\"LLM_BASE_URL\"] = str(base_url)\n",
    "else:\n",
    "    os.environ.pop(\"LLM_BASE_URL\", None)\n",
    "\n",
    "print(f\"‚úÖ Using provider={os.getenv('LLM_PROVIDER')} | model={os.getenv('LLM_MODEL')} | base_url={os.getenv('LLM_BASE_URL')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5801de0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè† Project root: /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval\n",
      "üìç Working directory: /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval/experiments/llm_postfilter/notebooks\n",
      "üîë Provider: OpenAI | Model: gpt-4o | API key found: True\n",
      "üöÄ LLM Post-Filter Experiment Ready!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Add llm-postfilter modules to path\n",
    "project_root = Path.cwd().parent.parent.parent\n",
    "sys.path.append(str(project_root / \"src\"))\n",
    "\n",
    "# Import llm-postfilter pipeline components\n",
    "from llm_postfilter import (\n",
    "    GLITCHLLMFilter, \n",
    "    HybridEvaluator,\n",
    "    SecuritySmellPrompts,\n",
    "    SecuritySmell,\n",
    "    Provider,\n",
    ")\n",
    "\n",
    "print(f\"üè† Project root: {project_root}\")\n",
    "print(f\"üìç Working directory: {Path.cwd()}\")\n",
    "\n",
    "# Optional: set provider/model for downstream notebook via env\n",
    "os.environ[\"LLM_PROVIDER\"] = \"openai\"\n",
    "os.environ[\"LLM_MODEL\"] = \"gpt-4o\"\n",
    "\n",
    "# Provider/model selection via env vars with sensible defaults\n",
    "provider = os.getenv(\"LLM_PROVIDER\", Provider.OPENAI.value)\n",
    "model = os.getenv(\"LLM_MODEL\", \"gpt-4o-mini\")\n",
    "base_url = os.getenv(\"LLM_BASE_URL\")  # for ollama or openai-compatible\n",
    "\n",
    "# API keys per provider\n",
    "api_key = None\n",
    "if provider == Provider.OPENAI.value:\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    print(f\"üîë Provider: OpenAI | Model: {model} | API key found: {bool(api_key)}\")\n",
    "elif provider == Provider.ANTHROPIC.value:\n",
    "    api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    print(f\"üîë Provider: Anthropic | Model: {model} | API key found: {bool(api_key)}\")\n",
    "elif provider == Provider.OLLAMA.value:\n",
    "    print(f\"üîë Provider: Ollama | Model: {model} | Base URL: {base_url or 'http://localhost:11434'}\")\n",
    "elif provider == Provider.OPENAI_COMPATIBLE.value:\n",
    "    api_key = os.getenv(\"OPENAI_COMPATIBLE_API_KEY\")\n",
    "    print(f\"üîë Provider: OpenAI-compatible | Model: {model} | Base URL: {base_url}\")\n",
    "else:\n",
    "    print(f\"‚ùå Unsupported provider: {provider}\")\n",
    "\n",
    "print(\"üöÄ LLM Post-Filter Experiment Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa31952a",
   "metadata": {},
   "source": [
    "## üìÅ Step 1: Load Context-Enhanced Data\n",
    "\n",
    "**Load detection files with code context prepared by 01_data_extraction.py**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "155fabcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Found 6 context-enhanced files:\n",
      "  üìÑ puppet_suspicious_comment_detections_with_context.csv: 23 detections (9 TP, 14 FP, 23 with context)\n",
      "  üìÑ puppet_use_of_weak_cryptography_algorithms_detections_with_context.csv: 7 detections (4 TP, 3 FP, 7 with context)\n",
      "  üìÑ puppet_hard_coded_secret_detections_with_context.csv: 66 detections (9 TP, 57 FP, 66 with context)\n",
      "  üìÑ chef_use_of_weak_cryptography_algorithms_detections_with_context.csv: 2 detections (1 TP, 1 FP, 2 with context)\n",
      "  üìÑ chef_hard_coded_secret_detections_with_context.csv: 46 detections (9 TP, 37 FP, 46 with context)\n",
      "  üìÑ chef_suspicious_comment_detections_with_context.csv: 10 detections (4 TP, 6 FP, 10 with context)\n",
      "\n",
      "‚úÖ Context-enhanced data ready for LLM analysis\n"
     ]
    }
   ],
   "source": [
    "# Setup directories\n",
    "data_dir = project_root / \"experiments/llm_postfilter/data\"\n",
    "context_dir = data_dir / \"with_context\"\n",
    "\n",
    "# Find context-enhanced files\n",
    "context_enhanced_files = list(context_dir.glob(\"*_with_context.csv\"))\n",
    "\n",
    "if context_enhanced_files:\n",
    "    print(f\"üìÅ Found {len(context_enhanced_files)} context-enhanced files:\")\n",
    "    for file in context_enhanced_files:\n",
    "        df = pd.read_csv(file)\n",
    "        tp_count = df['is_true_positive'].sum()\n",
    "        fp_count = len(df) - tp_count\n",
    "        context_success = df['context_success'].sum()\n",
    "        print(f\"  üìÑ {file.name}: {len(df)} detections ({tp_count} TP, {fp_count} FP, {context_success} with context)\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Context-enhanced data ready for LLM analysis\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No context-enhanced files found!\")\n",
    "    print(\"‚û°Ô∏è  Run 01_data_extraction.py first to prepare the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d79241f",
   "metadata": {},
   "source": [
    "## üìù Step 2: Review LLM Prompt Design\n",
    "\n",
    "Review the formal security smell definitions used for LLM evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "449ee4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Security Smell Definitions for LLM\n",
      "========================================\n",
      "\n",
      "üìå Hard-coded secret\n",
      "  A hard-coded secret is a security vulnerability where sensitive information such as passwords, API keys, tokens, certificates, or other credentials are directly embedded in the source code as literal strings or variables, rather than being securely stored and retrieved from external configuration systems, environment variables, or secret management services.\n",
      "  \n",
      "  Key characteristics:\n",
      "  ... (128 words total)\n",
      "\n",
      "üìå Suspicious comment\n",
      "  A suspicious comment is a code comment that indicates potential security issues, incomplete security implementations, or areas requiring security attention. These comments often signal unfinished work, security bypasses, or acknowledged vulnerabilities that may pose risks.\n",
      "  \n",
      "  Key characteristics:\n",
      "  ... (119 words total)\n",
      "\n",
      "üìå Use of weak cryptography algorithms\n",
      "  Use of weak cryptography algorithms refers to the implementation or configuration of cryptographic functions that are known to be vulnerable, deprecated, or insufficient for current security standards. This includes both algorithmically weak ciphers and poor cryptographic practices.\n",
      "  \n",
      "  Key characteristics:\n",
      "  ... (133 words total)\n",
      "\n",
      "‚úÖ 3 smell categories with formal definitions ready\n"
     ]
    }
   ],
   "source": [
    "# Display formal definitions for each security smell\n",
    "print(\"üìù Security Smell Definitions for LLM\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for smell in SecuritySmell:\n",
    "    definition = SecuritySmellPrompts.DEFINITIONS[smell]\n",
    "    lines = definition.strip().split('\\n')[:3]\n",
    "    print(f\"\\nüìå {smell.value}\")\n",
    "    for line in lines:\n",
    "        print(f\"  {line}\")\n",
    "    print(f\"  ... ({len(definition.split())} words total)\")\n",
    "\n",
    "print(f\"\\n‚úÖ {len(SecuritySmell)} smell categories with formal definitions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf30b6d",
   "metadata": {},
   "source": [
    "## üîß Step 3: Initialize LLM Pipeline\n",
    "\n",
    "Setup GLITCH+LLM hybrid detection pipeline with the selected provider/model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89029028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 14:12:46,791 - llm_postfilter.llm_client - INFO - Initialized OpenAI client with model: gpt-4o-mini\n",
      "2025-08-10 14:12:46,793 - llm_postfilter.llm_filter - INFO - Initialized GLITCH+LLM filter pipeline\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Initializing GLITCH+LLM pipeline...\n",
      "‚úÖ Pipeline ready:\n",
      "  ü§ñ Provider: openai\n",
      "  ü§ñ Model: gpt-4o-mini\n",
      "  üìä Results ‚Üí /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval/experiments/llm_postfilter/data/llm_results\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM filter pipeline\n",
    "# For OpenAI/Anthropic/OpenAI-compatible, an API key is required; for Ollama, it's not\n",
    "if (provider == Provider.OLLAMA.value) or (api_key):\n",
    "    print(\"üîß Initializing GLITCH+LLM pipeline...\")\n",
    "    \n",
    "    llm_filter = GLITCHLLMFilter(\n",
    "        project_root=project_root,\n",
    "        api_key=api_key,\n",
    "        model=model,\n",
    "        provider=provider,\n",
    "        base_url=base_url,\n",
    "    )\n",
    "    evaluator = HybridEvaluator(project_root)\n",
    "    \n",
    "    # Setup directories\n",
    "    results_dir = data_dir / \"llm_results\"\n",
    "    results_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    print(\"‚úÖ Pipeline ready:\")\n",
    "    print(f\"  ü§ñ Provider: {provider}\")\n",
    "    print(f\"  ü§ñ Model: {llm_filter.llm_client.model}\")\n",
    "    print(f\"  üìä Results ‚Üí {results_dir}\")\n",
    "else:\n",
    "    print(\"‚ùå Pipeline initialization failed - missing credentials\")\n",
    "    print(\"Set appropriate API key env var (OPENAI_API_KEY / ANTHROPIC_API_KEY / OPENAI_COMPATIBLE_API_KEY) or use Ollama\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891df435",
   "metadata": {},
   "source": [
    "## üöÄ Step 4: Run LLM Post-Filtering\n",
    "\n",
    "Apply LLM post-filtering to GLITCH detections and measure improvements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b00380",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ((provider == Provider.OLLAMA.value) or api_key) and 'context_enhanced_files' in locals():\n",
    "    print(f\"üîç Processing {len(context_enhanced_files)} context-enhanced files:\")\n",
    "    for file in context_enhanced_files:\n",
    "        df = pd.read_csv(file)\n",
    "        tp_count = df['is_true_positive'].sum()\n",
    "        fp_count = len(df) - tp_count\n",
    "        context_success = df['context_success'].sum()\n",
    "        print(f\"  üìÅ {file.name}: {len(df)} detections ({tp_count} TP, {fp_count} FP)\")\n",
    "    \n",
    "    print(f\"\\nüöÄ Starting LLM post-filtering...\")\n",
    "    \n",
    "    # Process each context-enhanced file\n",
    "    filtered_results = {}\n",
    "    \n",
    "    for i, context_file in enumerate(context_enhanced_files):\n",
    "        print(f\"\\nüîÑ Processing {i+1}/{len(context_enhanced_files)}: {context_file.name}\")\n",
    "        \n",
    "        try:\n",
    "            # Run LLM filtering\n",
    "            filtered_df = llm_filter.filter_detections(context_file, results_dir)\n",
    "            filtered_results[context_file.stem] = filtered_df\n",
    "            \n",
    "            # Summary stats\n",
    "            total = len(filtered_df)\n",
    "            kept = filtered_df['keep_detection'].sum()\n",
    "            original_tp = filtered_df['is_true_positive'].sum() \n",
    "            kept_tp = filtered_df[filtered_df['keep_detection']]['is_true_positive'].sum()\n",
    "            \n",
    "            print(f\"‚úÖ Kept {kept}/{total} ({kept/total:.1%}) | TP retention: {kept_tp}/{original_tp} ({kept_tp/original_tp:.1%})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            logger.error(f\"Failed to process {context_file}: {e}\")\n",
    "    \n",
    "    print(f\"\\nüéâ LLM filtering completed! Results ‚Üí {results_dir}\")\n",
    "    \n",
    "elif provider != Provider.OLLAMA.value and not api_key:\n",
    "    print(\"‚ùå Skipping - API key required for selected provider\")\n",
    "else:\n",
    "    print(\"‚ùå Skipping - no context files (run context extraction first)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef5c3aa",
   "metadata": {},
   "source": [
    "## üìà Step 5: Evaluate Performance Improvement\n",
    "\n",
    "Calculate precision, recall, and F1 improvements from LLM post-filtering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc577f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "if api_key and 'filtered_results' in locals():\n",
    "    print(\"üìä Evaluating GLITCH vs GLITCH+LLM Performance\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Organize results by IaC tool\n",
    "    evaluation_results = {}\n",
    "    \n",
    "    for tool in ['chef', 'puppet']:\n",
    "        tool_filtered_dfs = []\n",
    "        for key, filtered_df in filtered_results.items():\n",
    "            if key.startswith(tool):\n",
    "                tool_filtered_dfs.append(filtered_df)\n",
    "        \n",
    "        if tool_filtered_dfs:\n",
    "            tool_results = evaluator.evaluate_iac_tool(tool_filtered_dfs, tool.title())\n",
    "            evaluation_results[tool] = tool_results\n",
    "    \n",
    "    # Save evaluation results\n",
    "    evaluation_dir = results_dir / \"evaluation\"\n",
    "    evaluation_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    if evaluation_results:\n",
    "        summary_df = evaluator.save_evaluation_results(evaluation_results, evaluation_dir)\n",
    "        \n",
    "        print(\"\\nüéØ EXPERIMENT RESULTS\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        # Display key findings\n",
    "        for _, row in summary_df.iterrows():\n",
    "            tool = row['IaC_Tool']\n",
    "            smell = row['Security_Smell']\n",
    "            baseline_precision = row['Baseline_Precision']\n",
    "            llm_precision = row['LLM_Precision']\n",
    "            precision_improvement = row['Precision_Improvement']\n",
    "            fp_reduction = row['FP_Reduction']\n",
    "            tp_retention = row['TP_Retention']\n",
    "            \n",
    "            print(f\"\\nüìå {tool} - {smell}:\")\n",
    "            print(f\"  Precision: {baseline_precision:.3f} ‚Üí {llm_precision:.3f} ({precision_improvement:+.1%})\")\n",
    "            print(f\"  FP‚Üì: {fp_reduction:.1%} | TP retained: {tp_retention:.1%}\")\n",
    "        \n",
    "        # Overall improvements\n",
    "        avg_precision_improvement = summary_df['Precision_Improvement'].mean()\n",
    "        avg_fp_reduction = summary_df['FP_Reduction'].mean()\n",
    "        avg_tp_retention = summary_df['TP_Retention'].mean()\n",
    "        \n",
    "        print(f\"\\nüöÄ OVERALL OUTCOMES:\")\n",
    "        print(f\"  üìà Precision improvement: {avg_precision_improvement:+.1%}\")\n",
    "        print(f\"  üìâ FP reduction: {avg_fp_reduction:.1%}\")\n",
    "        print(f\"  üéØ TP retention: {avg_tp_retention:.1%}\")\n",
    "        \n",
    "        print(f\"\\nüíæ Detailed results ‚Üí {evaluation_dir}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå No evaluation results available\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Skipping evaluation - run LLM filtering first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224034f6",
   "metadata": {},
   "source": [
    "## üìÅ Generated Files & Transparency\n",
    "\n",
    "Complete experimental transparency through intermediate files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7ad639",
   "metadata": {
    "lines_to_next_cell": 3
   },
   "outputs": [],
   "source": [
    "print(\"üìÅ Generated Files & Transparency\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(\"\\nüîç Context Files (LLM input):\")\n",
    "if 'context_dir' in locals():\n",
    "    context_files = list(context_dir.glob(\"*.csv\"))\n",
    "    for file in context_files:\n",
    "        size_kb = file.stat().st_size // 1024\n",
    "        print(f\"  üìÑ {file.name} ({size_kb} KB)\")\n",
    "    print(f\"  üìÅ {context_dir}\")\n",
    "else:\n",
    "    print(\"  ‚ùå No context files generated\")\n",
    "\n",
    "print(\"\\nü§ñ LLM Results:\")\n",
    "if 'results_dir' in locals() and results_dir.exists():\n",
    "    result_files = list(results_dir.glob(\"*.csv\")) + list(results_dir.glob(\"*.json\"))\n",
    "    for file in result_files:\n",
    "        size_kb = file.stat().st_size // 1024\n",
    "        if file.name.endswith(\"_prompts_and_responses.json\"):\n",
    "            print(f\"  üìù {file.name} ({size_kb} KB) - Full prompts & LLM responses\")\n",
    "        elif file.name.endswith(\"_llm_filtered.csv\"):\n",
    "            print(f\"  üìä {file.name} ({size_kb} KB) - Filtered detections\")\n",
    "        else:\n",
    "            print(f\"  üìÑ {file.name} ({size_kb} KB)\")\n",
    "    print(f\"  üìÅ {results_dir}\")\n",
    "else:\n",
    "    print(\"  ‚ùå No LLM results generated\")\n",
    "\n",
    "print(\"\\nüìä Evaluation:\")\n",
    "if 'evaluation_dir' in locals() and evaluation_dir.exists():\n",
    "    eval_files = list(evaluation_dir.glob(\"*.csv\")) + list(evaluation_dir.glob(\"*.json\"))\n",
    "    for file in eval_files:\n",
    "        size_kb = file.stat().st_size // 1024\n",
    "        print(f\"  üìÑ {file.name} ({size_kb} KB)\")\n",
    "    print(f\"  üìÅ {evaluation_dir}\")\n",
    "else:\n",
    "    print(\"  ‚ùå No evaluation results generated\")\n",
    "\n",
    "print(\"\\nüí° Full transparency: code snippets, prompts, LLM decisions, metrics\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
