{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e32593d",
   "metadata": {},
   "source": [
    "# ğŸ¤– LLM Post-Filter Experiment: GLITCH+LLM Pipeline\n",
    "\n",
    "**Focus**: Evaluate **GLITCH + LLM** hybrid approach vs **GLITCH-only** baseline.\n",
    "\n",
    "## ğŸ”¬ Experiment Pipeline:\n",
    "\n",
    "1. **Data Preparation**: GLITCH detections + context extracted *(01_data_extraction.py)*\n",
    "2. **LLM Filtering**: Apply the selected LLM post-filtering  \n",
    "3. **Performance Evaluation**: Calculate precision/recall improvements\n",
    "\n",
    "## ğŸ¯ Expected Outcomes:\n",
    "- **Precision**: 50-300% improvement\n",
    "- **Recall**: >90% retention  \n",
    "- **FP Reduction**: Significant decrease in false alarms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e52b23a",
   "metadata": {},
   "source": [
    "## ğŸ”§ Setup and Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe85201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ Manual provider/model override (optional)\n",
    "# Edit these values to force a specific provider/model for this session.\n",
    "# Supported providers: \"openai\", \"anthropic\", \"ollama\", \"openai_compatible\"\n",
    "provider = \"openai\"\n",
    "model = \"gpt-4o-mini\"   # examples: \"gpt-4o\", \"claude-3-5-sonnet-latest\", \"codellama:7b\"\n",
    "base_url = None          # for ollama or openai-compatible, e.g. \"http://localhost:11434\" or \"https://api.x.ai/v1\"\n",
    "\n",
    "import os\n",
    "os.environ[\"LLM_PROVIDER\"] = provider\n",
    "os.environ[\"LLM_MODEL\"] = model\n",
    "if base_url:\n",
    "    os.environ[\"LLM_BASE_URL\"] = str(base_url)\n",
    "else:\n",
    "    os.environ.pop(\"LLM_BASE_URL\", None)\n",
    "\n",
    "print(f\"âœ… Using provider={os.getenv('LLM_PROVIDER')} | model={os.getenv('LLM_MODEL')} | base_url={os.getenv('LLM_BASE_URL')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d04086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ Prompt Style Configuration\n",
    "# Choose between \"definition_based\" (current approach) and \"static_analysis_rules\" (new approach)\n",
    "PROMPT_STYLE = \"static_analysis_rules\"  # Options: \"definition_based\", \"static_analysis_rules\"\n",
    "\n",
    "print(f\"ğŸ¯ Prompt style: {PROMPT_STYLE}\")\n",
    "print(\"Available styles:\")\n",
    "print(\"  ğŸ“š definition_based: Uses natural language definitions and characteristics\")\n",
    "print(\"  âš™ï¸ static_analysis_rules: Uses logical conditions and keyword-based detection rules\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5990aaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” Context window configuration (lines around target; use 0 for target-only)\n",
    "CONTEXT_LINES = 3  # change to 0, 1, 2, ... as needed\n",
    "print(f\"Context lines: Â±{CONTEXT_LINES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5801de0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Add llm-postfilter modules to path\n",
    "project_root = Path.cwd().parent.parent.parent\n",
    "sys.path.append(str(project_root / \"src\"))\n",
    "\n",
    "# Import llm-postfilter pipeline components\n",
    "from llm_postfilter import (\n",
    "    GLITCHLLMFilter, \n",
    "    HybridEvaluator,\n",
    "    SecuritySmellPrompts,\n",
    "    SecuritySmell,\n",
    "    PromptStyle,\n",
    "    Provider,\n",
    ")\n",
    "\n",
    "print(f\"ğŸ  Project root: {project_root}\")\n",
    "print(f\"ğŸ“ Working directory: {Path.cwd()}\")\n",
    "\n",
    "# Provider/model selection via env vars with sensible defaults\n",
    "provider = os.getenv(\"LLM_PROVIDER\", Provider.OPENAI.value)\n",
    "model = os.getenv(\"LLM_MODEL\", \"gpt-4o-mini\")\n",
    "base_url = os.getenv(\"LLM_BASE_URL\")  # for ollama or openai-compatible\n",
    "\n",
    "# API keys per provider\n",
    "api_key = None\n",
    "if provider == Provider.OPENAI.value:\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    print(f\"ğŸ”‘ Provider: OpenAI | Model: {model} | API key found: {bool(api_key)}\")\n",
    "elif provider == Provider.ANTHROPIC.value:\n",
    "    api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    print(f\"ğŸ”‘ Provider: Anthropic | Model: {model} | API key found: {bool(api_key)}\")\n",
    "elif provider == Provider.OLLAMA.value:\n",
    "    print(f\"ğŸ”‘ Provider: Ollama | Model: {model} | Base URL: {base_url or 'http://localhost:11434'}\")\n",
    "elif provider == Provider.OPENAI_COMPATIBLE.value:\n",
    "    api_key = os.getenv(\"OPENAI_COMPATIBLE_API_KEY\")\n",
    "    print(f\"ğŸ”‘ Provider: OpenAI-compatible | Model: {model} | Base URL: {base_url}\")\n",
    "else:\n",
    "    print(f\"âŒ Unsupported provider: {provider}\")\n",
    "\n",
    "print(\"ğŸš€ LLM Post-Filter Experiment Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa31952a",
   "metadata": {},
   "source": [
    "## ğŸ“ Step 1: Load Context-Enhanced Data\n",
    "\n",
    "**Load detection files with code context prepared by 01_data_extraction.py**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155fabcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup directories\n",
    "data_dir = project_root / \"experiments/llm_postfilter/data\"\n",
    "context_dir = data_dir / \"with_context\"\n",
    "\n",
    "# Find context-enhanced files\n",
    "context_enhanced_files = list(context_dir.glob(\"*_with_context.csv\"))\n",
    "\n",
    "if context_enhanced_files:\n",
    "    print(f\"ğŸ“ Found {len(context_enhanced_files)} context-enhanced files:\")\n",
    "    for file in context_enhanced_files:\n",
    "        df = pd.read_csv(file)\n",
    "        tp_count = df['is_true_positive'].sum()\n",
    "        fp_count = len(df) - tp_count\n",
    "        context_success = df['context_success'].sum()\n",
    "        print(f\"  ğŸ“„ {file.name}: {len(df)} detections ({tp_count} TP, {fp_count} FP, {context_success} with context)\")\n",
    "    \n",
    "    print(f\"\\nâœ… Context-enhanced data ready for LLM analysis\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ No context-enhanced files found!\")\n",
    "    print(\"â¡ï¸  Run 01_data_extraction.py first to prepare the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d79241f",
   "metadata": {},
   "source": [
    "## ğŸ“ Step 2: Review LLM Prompt Design\n",
    "\n",
    "Review the formal security smell definitions used for LLM evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222144ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” Prompt Style Demonstration\n",
    "print(\"ğŸ” PROMPT STYLE COMPARISON\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Sample code for demonstration\n",
    "sample_code = \"\"\"\n",
    "# File: database_config.rb\n",
    "    15: database_password = \"MySecretPassword123\"\n",
    ">>> 16: connection_string = \"mongodb://admin:#{database_password}@localhost:27017/mydb\"\n",
    "    17: Chef::Log.info(\"Connecting to database\")\n",
    "\"\"\"\n",
    "\n",
    "smell = SecuritySmell.HARD_CODED_SECRET\n",
    "\n",
    "# Show both prompt styles\n",
    "for style in PromptStyle:\n",
    "    print(f\"\\nğŸ“ {style.value.upper().replace('_', ' ')} STYLE:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    prompt = SecuritySmellPrompts.create_prompt(smell, sample_code, style)\n",
    "    \n",
    "    # Show first few lines to compare\n",
    "    lines = prompt.split('\\n')[:8]\n",
    "    for line in lines:\n",
    "        print(f\"  {line}\")\n",
    "    \n",
    "    print(f\"  ... ({len(prompt)} total characters)\")\n",
    "    \n",
    "print(f\"\\nğŸ¯ Current configuration uses: {PROMPT_STYLE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449ee4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display formal definitions for each security smell\n",
    "print(\"ğŸ“ Security Smell Definitions for LLM\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for smell in SecuritySmell:\n",
    "    definition = SecuritySmellPrompts.DEFINITIONS[smell]\n",
    "    lines = definition.strip().split('\\n')[:3]\n",
    "    print(f\"\\nğŸ“Œ {smell.value}\")\n",
    "    for line in lines:\n",
    "        print(f\"  {line}\")\n",
    "    print(f\"  ... ({len(definition.split())} words total)\")\n",
    "\n",
    "print(f\"\\nâœ… {len(SecuritySmell)} smell categories with formal definitions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf30b6d",
   "metadata": {},
   "source": [
    "## ğŸ”§ Step 3: Initialize LLM Pipeline\n",
    "\n",
    "Setup GLITCH+LLM hybrid detection pipeline with the selected provider/model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8c4881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM filter pipeline\n",
    "# For OpenAI/Anthropic/OpenAI-compatible, an API key is required; for Ollama, it's not\n",
    "if (provider == Provider.OLLAMA.value) or (api_key):\n",
    "    print(\"ğŸ”§ Initializing GLITCH+LLM pipeline...\")\n",
    "    \n",
    "    llm_filter = GLITCHLLMFilter(\n",
    "        project_root=project_root,\n",
    "        api_key=api_key,\n",
    "        model=model,\n",
    "        provider=provider,\n",
    "        base_url=base_url,\n",
    "        context_lines=CONTEXT_LINES,\n",
    "        prompt_style=PROMPT_STYLE,\n",
    "    )\n",
    "    evaluator = HybridEvaluator(project_root)\n",
    "    \n",
    "    # Setup directories\n",
    "    results_dir = data_dir / \"llm_results\"\n",
    "    results_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    print(\"âœ… Pipeline ready:\")\n",
    "    print(f\"  ğŸ¤– Provider: {provider}\")\n",
    "    print(f\"  ğŸ¤– Model: {llm_filter.llm_client.model}\")\n",
    "    print(f\"  ğŸ§© Context lines: Â±{llm_filter.context_lines}\")\n",
    "    print(f\"  ğŸ¯ Prompt style: {llm_filter.prompt_style.value}\")\n",
    "    print(f\"  ğŸ“Š Results â†’ {results_dir}\")\n",
    "else:\n",
    "    print(\"âŒ Pipeline initialization failed - missing credentials\")\n",
    "    print(\"Set appropriate API key env var (OPENAI_API_KEY / ANTHROPIC_API_KEY / OPENAI_COMPATIBLE_API_KEY) or use Ollama\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891df435",
   "metadata": {},
   "source": [
    "## ğŸš€ Step 4: Run LLM Post-Filtering\n",
    "\n",
    "Apply LLM post-filtering to GLITCH detections and measure improvements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b00380",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ((provider == Provider.OLLAMA.value) or api_key) and 'context_enhanced_files' in locals():\n",
    "    print(f\"ğŸ” Processing {len(context_enhanced_files)} context-enhanced files:\")\n",
    "    for file in context_enhanced_files:\n",
    "        df = pd.read_csv(file)\n",
    "        tp_count = df['is_true_positive'].sum()\n",
    "        fp_count = len(df) - tp_count\n",
    "        context_success = df['context_success'].sum()\n",
    "        print(f\"  ğŸ“ {file.name}: {len(df)} detections ({tp_count} TP, {fp_count} FP)\")\n",
    "    \n",
    "    print(f\"\\nğŸš€ Starting LLM post-filtering...\")\n",
    "    \n",
    "    # Process each context-enhanced file\n",
    "    filtered_results = {}\n",
    "    \n",
    "    for i, context_file in enumerate(context_enhanced_files):\n",
    "        print(f\"\\nğŸ”„ Processing {i+1}/{len(context_enhanced_files)}: {context_file.name}\")\n",
    "        \n",
    "        try:\n",
    "            # Run LLM filtering\n",
    "            filtered_df = llm_filter.filter_detections(context_file, results_dir)\n",
    "            filtered_results[context_file.stem] = filtered_df\n",
    "            \n",
    "            # Summary stats\n",
    "            total = len(filtered_df)\n",
    "            kept = filtered_df['keep_detection'].sum()\n",
    "            original_tp = filtered_df['is_true_positive'].sum() \n",
    "            kept_tp = filtered_df[filtered_df['keep_detection']]['is_true_positive'].sum()\n",
    "            \n",
    "            print(f\"âœ… Kept {kept}/{total} ({kept/total:.1%}) | TP retention: {kept_tp}/{original_tp} ({kept_tp/original_tp:.1%})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error: {e}\")\n",
    "            logger.error(f\"Failed to process {context_file}: {e}\")\n",
    "    \n",
    "    print(f\"\\nğŸ‰ LLM filtering completed! Results â†’ {results_dir}\")\n",
    "    \n",
    "elif provider != Provider.OLLAMA.value and not api_key:\n",
    "    print(\"âŒ Skipping - API key required for selected provider\")\n",
    "else:\n",
    "    print(\"âŒ Skipping - no context files (run context extraction first)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef5c3aa",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Step 5: Evaluate Performance Improvement\n",
    "\n",
    "Calculate precision, recall, and F1 improvements from LLM post-filtering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc577f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "if api_key and 'filtered_results' in locals():\n",
    "    print(\"ğŸ“Š Evaluating GLITCH vs GLITCH+LLM Performance\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Organize results by IaC tool\n",
    "    evaluation_results = {}\n",
    "    \n",
    "    for tool in ['chef', 'puppet']:\n",
    "        tool_filtered_dfs = []\n",
    "        for key, filtered_df in filtered_results.items():\n",
    "            if key.startswith(tool):\n",
    "                tool_filtered_dfs.append(filtered_df)\n",
    "        \n",
    "        if tool_filtered_dfs:\n",
    "            tool_results = evaluator.evaluate_iac_tool(tool_filtered_dfs, tool.title())\n",
    "            evaluation_results[tool] = tool_results\n",
    "    \n",
    "    # Save evaluation results\n",
    "    evaluation_dir = results_dir / \"evaluation\"\n",
    "    evaluation_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    if evaluation_results:\n",
    "        summary_df = evaluator.save_evaluation_results(evaluation_results, evaluation_dir)\n",
    "        \n",
    "        print(\"\\nğŸ¯ EXPERIMENT RESULTS\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        # Display key findings\n",
    "        for _, row in summary_df.iterrows():\n",
    "            tool = row['IaC_Tool']\n",
    "            smell = row['Security_Smell']\n",
    "            baseline_precision = row['Baseline_Precision']\n",
    "            llm_precision = row['LLM_Precision']\n",
    "            precision_improvement = row['Precision_Improvement']\n",
    "            fp_reduction = row['FP_Reduction']\n",
    "            tp_retention = row['TP_Retention']\n",
    "            \n",
    "            print(f\"\\nğŸ“Œ {tool} - {smell}:\")\n",
    "            print(f\"  Precision: {baseline_precision:.3f} â†’ {llm_precision:.3f} ({precision_improvement:+.1%})\")\n",
    "            print(f\"  FPâ†“: {fp_reduction:.1%} | TP retained: {tp_retention:.1%}\")\n",
    "        \n",
    "        # Overall improvements\n",
    "        avg_precision_improvement = summary_df['Precision_Improvement'].mean()\n",
    "        avg_fp_reduction = summary_df['FP_Reduction'].mean()\n",
    "        avg_tp_retention = summary_df['TP_Retention'].mean()\n",
    "        \n",
    "        print(f\"\\nğŸš€ OVERALL OUTCOMES:\")\n",
    "        print(f\"  ğŸ“ˆ Precision improvement: {avg_precision_improvement:+.1%}\")\n",
    "        print(f\"  ğŸ“‰ FP reduction: {avg_fp_reduction:.1%}\")\n",
    "        print(f\"  ğŸ¯ TP retention: {avg_tp_retention:.1%}\")\n",
    "        \n",
    "        print(f\"\\nğŸ’¾ Detailed results â†’ {evaluation_dir}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ No evaluation results available\")\n",
    "        \n",
    "else:\n",
    "    print(\"â­ï¸ Skipping evaluation - run LLM filtering first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224034f6",
   "metadata": {},
   "source": [
    "## ğŸ“ Generated Files & Transparency\n",
    "\n",
    "Complete experimental transparency through intermediate files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7ad639",
   "metadata": {
    "lines_to_next_cell": 3
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ“ Generated Files & Transparency\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(\"\\nğŸ” Context Files (LLM input):\")\n",
    "if 'context_dir' in locals():\n",
    "    context_files = list(context_dir.glob(\"*.csv\"))\n",
    "    for file in context_files:\n",
    "        size_kb = file.stat().st_size // 1024\n",
    "        print(f\"  ğŸ“„ {file.name} ({size_kb} KB)\")\n",
    "    print(f\"  ğŸ“ {context_dir}\")\n",
    "else:\n",
    "    print(\"  âŒ No context files generated\")\n",
    "\n",
    "print(\"\\nğŸ¤– LLM Results:\")\n",
    "if 'results_dir' in locals() and results_dir.exists():\n",
    "    result_files = list(results_dir.glob(\"*.csv\")) + list(results_dir.glob(\"*.json\"))\n",
    "    for file in result_files:\n",
    "        size_kb = file.stat().st_size // 1024\n",
    "        if file.name.endswith(\"_prompts_and_responses.json\"):\n",
    "            print(f\"  ğŸ“ {file.name} ({size_kb} KB) - Full prompts & LLM responses\")\n",
    "        elif file.name.endswith(\"_llm_filtered.csv\"):\n",
    "            print(f\"  ğŸ“Š {file.name} ({size_kb} KB) - Filtered detections\")\n",
    "        else:\n",
    "            print(f\"  ğŸ“„ {file.name} ({size_kb} KB)\")\n",
    "    print(f\"  ğŸ“ {results_dir}\")\n",
    "else:\n",
    "    print(\"  âŒ No LLM results generated\")\n",
    "\n",
    "print(\"\\nğŸ“Š Evaluation:\")\n",
    "if 'evaluation_dir' in locals() and evaluation_dir.exists():\n",
    "    eval_files = list(evaluation_dir.glob(\"*.csv\")) + list(evaluation_dir.glob(\"*.json\"))\n",
    "    for file in eval_files:\n",
    "        size_kb = file.stat().st_size // 1024\n",
    "        print(f\"  ğŸ“„ {file.name} ({size_kb} KB)\")\n",
    "    print(f\"  ğŸ“ {evaluation_dir}\")\n",
    "else:\n",
    "    print(\"  âŒ No evaluation results generated\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Full transparency: code snippets, prompts, LLM decisions, metrics\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
