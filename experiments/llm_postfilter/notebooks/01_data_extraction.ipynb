{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da5d6f8a",
   "metadata": {},
   "source": [
    "# ğŸ“Š LLM Post-Filter Experiment: Data Extraction\n",
    "\n",
    "**Focus**: Extract GLITCH detections from baseline experiments for LLM evaluation.\n",
    "\n",
    "## ğŸ¯ Goals:\n",
    "1. Extract all TP/FP GLITCH detections from Chef and Puppet experiments\n",
    "2. Prepare clean dataset for LLM post-filtering pipeline\n",
    "3. Generate summary statistics for baseline performance\n",
    "\n",
    "## ğŸ“ Data Sources:\n",
    "- **Baseline Results**: Chef and Puppet static analysis experiments\n",
    "- **Target Smells**: Hard-coded secret, Suspicious comment, Weak cryptography\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e965a70",
   "metadata": {},
   "source": [
    "## ğŸ”§ Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "877082ca",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval\n",
      "Working directory: /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval/experiments/llm_postfilter/notebooks\n",
      "âœ… Data extractor initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the src directory to path to import our llm_postfilter modules\n",
    "project_root = Path.cwd().parent.parent.parent\n",
    "sys.path.append(str(project_root / \"src\"))\n",
    "\n",
    "from llm_postfilter.data_extractor import GLITCHDetectionExtractor\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Working directory: {Path.cwd()}\")\n",
    "\n",
    "# Initialize the extractor\n",
    "extractor = GLITCHDetectionExtractor(project_root)\n",
    "print(\"âœ… Data extractor initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaec477",
   "metadata": {},
   "source": [
    "## ğŸ“Š Extract Chef Detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa1e9df4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llm_postfilter.data_extractor:Loaded chef data: Oracle=148, GLITCH=166\n",
      "INFO:llm_postfilter.data_extractor:Hard-coded secret: 9 TP, 37 FP\n",
      "INFO:llm_postfilter.data_extractor:Suspicious comment: 4 TP, 6 FP\n",
      "INFO:llm_postfilter.data_extractor:Use of weak cryptography algorithms: 1 TP, 1 FP\n",
      "INFO:llm_postfilter.data_extractor:Extracted 46 detections for Hard-coded secret\n",
      "INFO:llm_postfilter.data_extractor:Extracted 10 detections for Suspicious comment\n",
      "INFO:llm_postfilter.data_extractor:Extracted 2 detections for Use of weak cryptography algorithms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Extracting Chef detections...\n",
      "\n",
      "ğŸ“Š Chef Detection Summary:\n",
      "  Hard-coded secret: 46 total | 9 TP | 37 FP\n",
      "  Suspicious comment: 10 total | 4 TP | 6 FP\n",
      "  Use of weak cryptography algorithms: 2 total | 1 TP | 1 FP\n",
      "\n",
      "ğŸ“ Example detection structure:\n",
      "  detection_id: chef_Hard-coded secret_chef-boneyard_qa-chef-server-cluster-attributes-default.rb_3\n",
      "  iac_tool: chef\n",
      "  smell_category: Hard-coded secret\n",
      "  glitch_smell: hardcoded-secret\n",
      "  file_path: chef-boneyard_qa-chef-server-cluster-attributes-default.rb\n",
      "  line_number: 3\n",
      "  detection_id_raw: chef-boneyard_qa-chef-server-cluster-attributes-default.rb_3\n",
      "  is_true_positive: True\n",
      "  glitch_detection: True\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ” Extracting Chef detections...\")\n",
    "\n",
    "chef_detections = extractor.extract_detections_for_llm('chef')\n",
    "\n",
    "print(f\"\\nğŸ“Š Chef Detection Summary:\")\n",
    "for smell, detections in chef_detections.items():\n",
    "    tp_count = sum(1 for d in detections if d['is_true_positive'])\n",
    "    fp_count = sum(1 for d in detections if not d['is_true_positive'])\n",
    "    print(f\"  {smell}: {len(detections)} total | {tp_count} TP | {fp_count} FP\")\n",
    "\n",
    "# Show example detection structure\n",
    "if chef_detections:\n",
    "    first_smell = next(iter(chef_detections.keys()))\n",
    "    if chef_detections[first_smell]:\n",
    "        print(f\"\\nğŸ“ Example detection structure:\")\n",
    "        example = chef_detections[first_smell][0]\n",
    "        for key, value in example.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  No detections found for {first_smell}\")\n",
    "else:\n",
    "    print(\"\\nâŒ No detections extracted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36256169",
   "metadata": {},
   "source": [
    "## ğŸ“Š Extract Puppet Detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "043301bc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llm_postfilter.data_extractor:Loaded puppet data: Oracle=117, GLITCH=197\n",
      "INFO:llm_postfilter.data_extractor:Hard-coded secret: 9 TP, 57 FP\n",
      "INFO:llm_postfilter.data_extractor:Suspicious comment: 9 TP, 14 FP\n",
      "INFO:llm_postfilter.data_extractor:Use of weak cryptography algorithms: 4 TP, 3 FP\n",
      "INFO:llm_postfilter.data_extractor:Extracted 66 detections for Hard-coded secret\n",
      "INFO:llm_postfilter.data_extractor:Extracted 23 detections for Suspicious comment\n",
      "INFO:llm_postfilter.data_extractor:Extracted 7 detections for Use of weak cryptography algorithms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Extracting Puppet detections...\n",
      "\n",
      "ğŸ“Š Puppet Detection Summary:\n",
      "  Hard-coded secret: 66 total | 9 TP | 57 FP\n",
      "  Suspicious comment: 23 total | 9 TP | 14 FP\n",
      "  Use of weak cryptography algorithms: 7 total | 4 TP | 3 FP\n",
      "\n",
      "ğŸ”„ Chef vs Puppet Comparison:\n",
      "  Hard-coded secret: Chef=46, Puppet=66\n",
      "  Suspicious comment: Chef=10, Puppet=23\n",
      "  Use of weak cryptography algorithms: Chef=2, Puppet=7\n",
      "\n",
      "âœ… Total detections extracted: 154\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ” Extracting Puppet detections...\")\n",
    "\n",
    "puppet_detections = extractor.extract_detections_for_llm('puppet')\n",
    "\n",
    "print(f\"\\nğŸ“Š Puppet Detection Summary:\")\n",
    "for smell, detections in puppet_detections.items():\n",
    "    tp_count = sum(1 for d in detections if d['is_true_positive'])\n",
    "    fp_count = sum(1 for d in detections if not d['is_true_positive'])\n",
    "    print(f\"  {smell}: {len(detections)} total | {tp_count} TP | {fp_count} FP\")\n",
    "\n",
    "# Cross-tool comparison\n",
    "print(f\"\\nğŸ”„ Chef vs Puppet Comparison:\")\n",
    "all_smells = set(chef_detections.keys()) | set(puppet_detections.keys())\n",
    "for smell in sorted(all_smells):\n",
    "    chef_count = len(chef_detections.get(smell, []))\n",
    "    puppet_count = len(puppet_detections.get(smell, []))\n",
    "    print(f\"  {smell}: Chef={chef_count}, Puppet={puppet_count}\")\n",
    "\n",
    "total_detections = (sum(len(detections) for detections in chef_detections.values()) + \n",
    "                   sum(len(detections) for detections in puppet_detections.values()))\n",
    "print(f\"\\nâœ… Total detections extracted: {total_detections}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa9e84f",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Save Detection Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9711a9f4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llm_postfilter.data_extractor:Loaded chef data: Oracle=148, GLITCH=166\n",
      "INFO:llm_postfilter.data_extractor:Hard-coded secret: 9 TP, 37 FP\n",
      "INFO:llm_postfilter.data_extractor:Suspicious comment: 4 TP, 6 FP\n",
      "INFO:llm_postfilter.data_extractor:Use of weak cryptography algorithms: 1 TP, 1 FP\n",
      "INFO:llm_postfilter.data_extractor:Extracted 46 detections for Hard-coded secret\n",
      "INFO:llm_postfilter.data_extractor:Extracted 10 detections for Suspicious comment\n",
      "INFO:llm_postfilter.data_extractor:Extracted 2 detections for Use of weak cryptography algorithms\n",
      "INFO:llm_postfilter.data_extractor:Saved 46 detections to /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval/experiments/llm_postfilter/data/chef_hard_coded_secret_detections.csv\n",
      "INFO:llm_postfilter.data_extractor:Saved 10 detections to /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval/experiments/llm_postfilter/data/chef_suspicious_comment_detections.csv\n",
      "INFO:llm_postfilter.data_extractor:Saved 2 detections to /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval/experiments/llm_postfilter/data/chef_use_of_weak_cryptography_algorithms_detections.csv\n",
      "INFO:llm_postfilter.data_extractor:Saved summary to /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval/experiments/llm_postfilter/data/chef_detection_summary.csv\n",
      "INFO:llm_postfilter.data_extractor:Loaded puppet data: Oracle=117, GLITCH=197\n",
      "INFO:llm_postfilter.data_extractor:Hard-coded secret: 9 TP, 57 FP\n",
      "INFO:llm_postfilter.data_extractor:Suspicious comment: 9 TP, 14 FP\n",
      "INFO:llm_postfilter.data_extractor:Use of weak cryptography algorithms: 4 TP, 3 FP\n",
      "INFO:llm_postfilter.data_extractor:Extracted 66 detections for Hard-coded secret\n",
      "INFO:llm_postfilter.data_extractor:Extracted 23 detections for Suspicious comment\n",
      "INFO:llm_postfilter.data_extractor:Extracted 7 detections for Use of weak cryptography algorithms\n",
      "INFO:llm_postfilter.data_extractor:Saved 66 detections to /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval/experiments/llm_postfilter/data/puppet_hard_coded_secret_detections.csv\n",
      "INFO:llm_postfilter.data_extractor:Saved 23 detections to /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval/experiments/llm_postfilter/data/puppet_suspicious_comment_detections.csv\n",
      "INFO:llm_postfilter.data_extractor:Saved 7 detections to /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval/experiments/llm_postfilter/data/puppet_use_of_weak_cryptography_algorithms_detections.csv\n",
      "INFO:llm_postfilter.data_extractor:Saved summary to /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval/experiments/llm_postfilter/data/puppet_detection_summary.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Saving detection dataset...\n",
      "âœ… Detection files saved:\n",
      "  ğŸ“„ chef_hard_coded_secret_detections.csv: 46 detections (12,068 bytes)\n",
      "  ğŸ“„ chef_suspicious_comment_detections.csv: 10 detections (3,176 bytes)\n",
      "  ğŸ“„ chef_use_of_weak_cryptography_algorithms_detections.csv: 2 detections (795 bytes)\n",
      "  ğŸ“„ puppet_hard_coded_secret_detections.csv: 66 detections (18,591 bytes)\n",
      "  ğŸ“„ puppet_suspicious_comment_detections.csv: 23 detections (6,281 bytes)\n",
      "  ğŸ“„ puppet_use_of_weak_cryptography_algorithms_detections.csv: 7 detections (2,504 bytes)\n",
      "\n",
      "ğŸ¯ Dataset ready for LLM post-filtering pipeline!\n",
      "ğŸ“ Location: /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval/experiments/llm_postfilter/data\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ’¾ Saving detection dataset...\")\n",
    "\n",
    "output_dir = project_root / \"experiments/llm_postfilter/data\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save detection files\n",
    "chef_saved = extractor.save_detections('chef', output_dir)\n",
    "puppet_saved = extractor.save_detections('puppet', output_dir)\n",
    "\n",
    "print(f\"âœ… Detection files saved:\")\n",
    "for file_path in sorted(output_dir.glob(\"*_detections.csv\")):\n",
    "    file_size = file_path.stat().st_size\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"  ğŸ“„ {file_path.name}: {len(df)} detections ({file_size:,} bytes)\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Dataset ready for LLM post-filtering pipeline!\")\n",
    "print(f\"ğŸ“ Location: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c744a2b9",
   "metadata": {},
   "source": [
    "## ğŸ” Extract Code Context for LLM Analysis\n",
    "\n",
    "**Extract Â±3 lines of code context around each GLITCH detection for LLM evaluation.**\n",
    "\n",
    "This provides transparent, analyzable code snippets for the LLM post-filtering pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a42ee8f7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Found 6 detection files:\n",
      "  ğŸ“„ puppet_hard_coded_secret_detections.csv: 66 detections (9 TP, 57 FP)\n",
      "  ğŸ“„ puppet_use_of_weak_cryptography_algorithms_detections.csv: 7 detections (4 TP, 3 FP)\n",
      "  ğŸ“„ puppet_suspicious_comment_detections.csv: 23 detections (9 TP, 14 FP)\n",
      "  ğŸ“„ chef_suspicious_comment_detections.csv: 10 detections (4 TP, 6 FP)\n",
      "  ğŸ“„ chef_use_of_weak_cryptography_algorithms_detections.csv: 2 detections (1 TP, 1 FP)\n",
      "  ğŸ“„ chef_hard_coded_secret_detections.csv: 46 detections (9 TP, 37 FP)\n",
      "\n",
      "ğŸ” Extracting code context for LLM analysis...\n"
     ]
    }
   ],
   "source": [
    "# Import context extractor\n",
    "from llm_postfilter.context_extractor import CodeContextExtractor\n",
    "\n",
    "# Setup directories\n",
    "context_dir = output_dir / \"with_context\"\n",
    "context_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Initialize context extractor\n",
    "context_extractor = CodeContextExtractor(project_root)\n",
    "\n",
    "# Find detection files to process\n",
    "detection_files = list(output_dir.glob(\"*_detections.csv\"))\n",
    "detection_files = [f for f in detection_files if not f.name.endswith(\"_with_context.csv\") and not f.name.endswith(\"_llm_filtered.csv\")]\n",
    "\n",
    "print(f\"ğŸ“ Found {len(detection_files)} detection files:\")\n",
    "for file in detection_files:\n",
    "    df = pd.read_csv(file)\n",
    "    tp_count = df['is_true_positive'].sum()\n",
    "    fp_count = len(df) - tp_count\n",
    "    print(f\"  ğŸ“„ {file.name}: {len(df)} detections ({tp_count} TP, {fp_count} FP)\")\n",
    "\n",
    "print(f\"\\nğŸ” Extracting code context for LLM analysis...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f71cbae2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llm_postfilter.context_extractor:Loaded 66 detections from puppet_hard_coded_secret_detections.csv\n",
      "INFO:llm_postfilter.context_extractor:Successfully extracted context for 66/66 detections\n",
      "INFO:llm_postfilter.context_extractor:Saved 66 detections with context to /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval/experiments/llm_postfilter/data/with_context/puppet_hard_coded_secret_detections_with_context.csv\n",
      "INFO:llm_postfilter.context_extractor:Context extraction success rate: 66/66 (100.0%)\n",
      "INFO:llm_postfilter.context_extractor:Loaded 7 detections from puppet_use_of_weak_cryptography_algorithms_detections.csv\n",
      "INFO:llm_postfilter.context_extractor:Successfully extracted context for 7/7 detections\n",
      "INFO:llm_postfilter.context_extractor:Saved 7 detections with context to /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval/experiments/llm_postfilter/data/with_context/puppet_use_of_weak_cryptography_algorithms_detections_with_context.csv\n",
      "INFO:llm_postfilter.context_extractor:Context extraction success rate: 7/7 (100.0%)\n",
      "INFO:llm_postfilter.context_extractor:Loaded 23 detections from puppet_suspicious_comment_detections.csv\n",
      "INFO:llm_postfilter.context_extractor:Successfully extracted context for 23/23 detections\n",
      "INFO:llm_postfilter.context_extractor:Saved 23 detections with context to /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval/experiments/llm_postfilter/data/with_context/puppet_suspicious_comment_detections_with_context.csv\n",
      "INFO:llm_postfilter.context_extractor:Context extraction success rate: 23/23 (100.0%)\n",
      "INFO:llm_postfilter.context_extractor:Loaded 10 detections from chef_suspicious_comment_detections.csv\n",
      "INFO:llm_postfilter.context_extractor:Successfully extracted context for 10/10 detections\n",
      "INFO:llm_postfilter.context_extractor:Saved 10 detections with context to /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval/experiments/llm_postfilter/data/with_context/chef_suspicious_comment_detections_with_context.csv\n",
      "INFO:llm_postfilter.context_extractor:Context extraction success rate: 10/10 (100.0%)\n",
      "INFO:llm_postfilter.context_extractor:Loaded 2 detections from chef_use_of_weak_cryptography_algorithms_detections.csv\n",
      "INFO:llm_postfilter.context_extractor:Successfully extracted context for 2/2 detections\n",
      "INFO:llm_postfilter.context_extractor:Saved 2 detections with context to /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval/experiments/llm_postfilter/data/with_context/chef_use_of_weak_cryptography_algorithms_detections_with_context.csv\n",
      "INFO:llm_postfilter.context_extractor:Context extraction success rate: 2/2 (100.0%)\n",
      "INFO:llm_postfilter.context_extractor:Loaded 46 detections from chef_hard_coded_secret_detections.csv\n",
      "INFO:llm_postfilter.context_extractor:Successfully extracted context for 46/46 detections\n",
      "INFO:llm_postfilter.context_extractor:Saved 46 detections with context to /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval/experiments/llm_postfilter/data/with_context/chef_hard_coded_secret_detections_with_context.csv\n",
      "INFO:llm_postfilter.context_extractor:Context extraction success rate: 46/46 (100.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ Processing 1/6: puppet_hard_coded_secret_detections.csv\n",
      "âœ… puppet_hard_coded_secret_detections_with_context.csv: 66/66 context extracted (100.0%)\n",
      "\n",
      "ğŸ”„ Processing 2/6: puppet_use_of_weak_cryptography_algorithms_detections.csv\n",
      "âœ… puppet_use_of_weak_cryptography_algorithms_detections_with_context.csv: 7/7 context extracted (100.0%)\n",
      "\n",
      "ğŸ”„ Processing 3/6: puppet_suspicious_comment_detections.csv\n",
      "âœ… puppet_suspicious_comment_detections_with_context.csv: 23/23 context extracted (100.0%)\n",
      "\n",
      "ğŸ”„ Processing 4/6: chef_suspicious_comment_detections.csv\n",
      "âœ… chef_suspicious_comment_detections_with_context.csv: 10/10 context extracted (100.0%)\n",
      "\n",
      "ğŸ”„ Processing 5/6: chef_use_of_weak_cryptography_algorithms_detections.csv\n",
      "âœ… chef_use_of_weak_cryptography_algorithms_detections_with_context.csv: 2/2 context extracted (100.0%)\n",
      "\n",
      "ğŸ”„ Processing 6/6: chef_hard_coded_secret_detections.csv\n",
      "âœ… chef_hard_coded_secret_detections_with_context.csv: 46/46 context extracted (100.0%)\n",
      "\n",
      "ğŸ¯ Context extraction completed for 6 files!\n"
     ]
    }
   ],
   "source": [
    "# Process each detection file and save context-enhanced versions\n",
    "context_enhanced_files = []\n",
    "context_stats = []\n",
    "\n",
    "for i, detection_file in enumerate(detection_files):\n",
    "    print(f\"\\nğŸ”„ Processing {i+1}/{len(detection_files)}: {detection_file.name}\")\n",
    "    \n",
    "    # Extract context and save enhanced file\n",
    "    enhanced_df = context_extractor.process_and_save_detections(\n",
    "        detection_file, context_dir, context_lines=3\n",
    "    )\n",
    "    \n",
    "    # Track files and stats\n",
    "    base_name = detection_file.stem\n",
    "    context_file = context_dir / f\"{base_name}_with_context.csv\"\n",
    "    context_enhanced_files.append(context_file)\n",
    "    \n",
    "    # Calculate stats\n",
    "    total_detections = len(enhanced_df)\n",
    "    successful_context = enhanced_df['context_success'].sum()\n",
    "    files_found = enhanced_df['file_found'].sum()\n",
    "    \n",
    "    context_stats.append({\n",
    "        'file': detection_file.name,\n",
    "        'total_detections': total_detections,\n",
    "        'files_found': files_found,\n",
    "        'context_extracted': successful_context,\n",
    "        'success_rate': successful_context / total_detections if total_detections > 0 else 0\n",
    "    })\n",
    "    \n",
    "    print(f\"âœ… {context_file.name}: {successful_context}/{total_detections} context extracted ({successful_context/total_detections:.1%})\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Context extraction completed for {len(detection_files)} files!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1b5379f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Context Extraction Summary\n",
      "==================================================\n",
      "ğŸ“„ puppet_hard_coded_secret_detections.csv: 66/66 (100.0%) context extracted\n",
      "ğŸ“„ puppet_use_of_weak_cryptography_algorithms_detections.csv: 7/7 (100.0%) context extracted\n",
      "ğŸ“„ puppet_suspicious_comment_detections.csv: 23/23 (100.0%) context extracted\n",
      "ğŸ“„ chef_suspicious_comment_detections.csv: 10/10 (100.0%) context extracted\n",
      "ğŸ“„ chef_use_of_weak_cryptography_algorithms_detections.csv: 2/2 (100.0%) context extracted\n",
      "ğŸ“„ chef_hard_coded_secret_detections.csv: 46/46 (100.0%) context extracted\n",
      "\n",
      "ğŸ¯ Overall: 154/154 (100.0%) successful\n",
      "ğŸ“ Context files saved: 6 â†’ /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval/experiments/llm_postfilter/data/with_context\n"
     ]
    }
   ],
   "source": [
    "# Display context extraction summary\n",
    "print(\"ğŸ“Š Context Extraction Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "stats_df = pd.DataFrame(context_stats)\n",
    "for _, row in stats_df.iterrows():\n",
    "    print(f\"ğŸ“„ {row['file']}: {row['context_extracted']}/{row['total_detections']} ({row['success_rate']:.1%}) context extracted\")\n",
    "\n",
    "# Overall statistics\n",
    "total_detections = stats_df['total_detections'].sum()\n",
    "total_context_extracted = stats_df['context_extracted'].sum()\n",
    "overall_success_rate = total_context_extracted / total_detections if total_detections > 0 else 0\n",
    "\n",
    "print(f\"\\nğŸ¯ Overall: {total_context_extracted}/{total_detections} ({overall_success_rate:.1%}) successful\")\n",
    "print(f\"ğŸ“ Context files saved: {len(context_enhanced_files)} â†’ {context_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06d8c369",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Example Context Snippet for LLM\n",
      "========================================\n",
      "ğŸ“ puppet_hard_coded_secret_detections_with_context.csv\n",
      "ğŸ¯ Hard-coded secret | TP: True\n",
      "\n",
      "ğŸ“„ Context Snippet:\n",
      "------------------------------\n",
      "# File: alphagov@govuk-puppet-modules-users-manifests-felisialoukou.pp\n",
      "# Target line: 5\n",
      "\n",
      "      2: class users::felisialoukou { govuk_user { 'felisialoukou':\n",
      "      3:     fullname => 'Felisia Loukou',\n",
      "      4:     email    => 'felisia.loukou@digital.cabinet-office.gov.uk',\n",
      ">>>   5:     ssh_key  => [\n",
      "      6:         'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDlxJNWiWOVbtSwe5DNNzN8csunIvCX6XUIAT141EjGZpOaEjK3yFtvv96OukdWTXPQXnWBDOIWg+fNJWc4LsfqnCV5CrHftykTqHeKakEcVX2aW5UrWvlOWHoTdkbFv+L67MaT2xIT/KWLYPliyZJOmwwF+W1kiFq3xVtI5qgMha7s2I3thuBo8lgLXsmxdVcYoa32MBKabNyknvZaF/l2l/D/wssbC/3N5zeLupJJXDRA4BWw6nqAW97AOceVH04twCG6+B5qL/M56D/YW8kMIx/XSSIAde4+yXCX0gLr5p4L6pNvD2vn/nJSY/rMDtO5rPX+XQjmM7eti50FvkflvGzuaUoSXb1sP+rwOtGMVQBn4pnB1whd8jZSQC+SRsXAgj7TgQfKLux/T00cq+pC09HrBPLag1TUcueJE65FM6mi2uyi+sYYOnVfr4ZhgiEBY+uFoOWl/TwnKuIAXXXD4aL9BXpOTdy3XxxEwHeobfv2AOa8QH8rGQXuXExTjaMXQEbQ6rnhUEmccu1fSTZt4rEUlv2a61Bp2XKcjvKNodNHqQwFXWbX+qmKpGTurPQZG9wqJzejUer1YYSuraxezQtSpM0ZREFhIQMSA5F137bCPVwLanJ3A/XN+1aEwjynrDALOmYOyJw/eblYCUX84At55tbDt+XdmIXiVeg0eQ== felisia.loukou@digital.cabinet-office.gov.uk',\n",
      "      7:     ],\n",
      "      8:   }\n",
      "------------------------------\n",
      "\n",
      "ğŸ’¡ All context files saved â†’ /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval/experiments/llm_postfilter/data/with_context\n",
      "\n",
      "ğŸ¯ Data preparation completed!\n",
      "ğŸ“ Detection files: /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval/experiments/llm_postfilter/data\n",
      "ğŸ“ Context files: /Users/colemei/Library/Mobile Documents/com~apple~CloudDocs/01.Work/04.Master/Course/Research Program/Project/LLM-IaC-SecEval/experiments/llm_postfilter/data/with_context\n",
      "\n",
      "â¡ï¸  Next: Run 02_llm_experiment.py for LLM evaluation\n"
     ]
    }
   ],
   "source": [
    "# Show example context snippet that LLM will analyze\n",
    "print(\"ğŸ” Example Context Snippet for LLM\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if context_enhanced_files:\n",
    "    example_file = context_enhanced_files[0]\n",
    "    example_df = pd.read_csv(example_file)\n",
    "    successful_detections = example_df[example_df['context_success'] == True]\n",
    "    \n",
    "    if len(successful_detections) > 0:\n",
    "        example = successful_detections.iloc[0]\n",
    "        print(f\"ğŸ“ {example_file.name}\")\n",
    "        print(f\"ğŸ¯ {example['smell_category']} | TP: {example['is_true_positive']}\")\n",
    "        print(f\"\\nğŸ“„ Context Snippet:\")\n",
    "        print(\"-\" * 30)\n",
    "        print(example['context_snippet'])\n",
    "        print(\"-\" * 30)\n",
    "    else:\n",
    "        print(\"âŒ No successful context extractions found\")\n",
    "else:\n",
    "    print(\"âŒ No context-enhanced files available\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ All context files saved â†’ {context_dir}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Data preparation completed!\")\n",
    "print(f\"ğŸ“ Detection files: {output_dir}\")\n",
    "print(f\"ğŸ“ Context files: {context_dir}\")\n",
    "print(f\"\\nâ¡ï¸  Next: Run 02_llm_experiment.py for LLM evaluation\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
